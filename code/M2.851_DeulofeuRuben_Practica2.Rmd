---
title: 'Tipología y ciclo de vida de los datos. Práctica 2.'
author: "Autor: Ruben Deulofeu Gomez"
date: "Enero 2021"
output:
  html_document:
    highlight: default
    number_sections: no
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```

```{r load_libraries, include=FALSE}
library(knitr)
library(stringr)
library(ggplot2)
library(grid)
library(gridExtra)
library(gmodels)
```

******
# 1. Descripción, importancia y utilidad del dataset
******
El dataset escogido para realizar esta práctica se encuentra en este enlace: https://www.kaggle.com/c/titanic/data. Se trata de información relativa a los pasajeros del Titanic. En particular, se ha escogido el fichero train.csv, que se encuentra en el enlace anterior y se ha renombrado como titanic.csv. 
Las variables que contiene el conjunto de datos son las siguientes: 

- PassengerId: número entero identificatorio del pasajero dentro del dataset.
- Survived: entero que nos informa si el pasajero sobrevivió o no. 1 = Si, 0 = No. 
- Pclass: entero que nos indica la clase del billete comprado por el pasajero. 1 = Primera clase, 2 = Segunda clase, 3 = Tercera clase.
- Name: nombre completo del pasajero. Expresado en cadena de caracteres.
- Sex: sexo del pasajero. Expresado en cadena de caracteres.
- Age: edad del pasajero. Expresado en variable numérica. 
- SibSp: entero que nos indica la cantidad de hermanos/cónyuges a bordo, del pasajero. 
- Parch: entero que nos indica la cantidad de padres/hijos a bordo, del pasajero. 
- Ticket: código alfanumérico que indentifica al pasajero. Expresado con cadena de caracteres.  
- Fare: precio del billete, (=0 para la tripulación). 
- Cabin: código alfanumérico que indica la cabina en la que se alojaba el pasajero. 
- Embarked: carácter que informa del puerto de embarque del pasajero. C = Cherbourg, Q = Queenstown, S = Southampton.

A partir de este juego de datos, se pretende averiguar que variables tienen más peso sobre la supervivencia del pasajero. 

Gracias a este tipo de análisis, se puede obtener información muy relevante sobre un hecho histórico, simplemente interpretando un dataset. Esto permite sacar conclusiones y descubrir más sobre qué paso aquella noche del 14 de abril de 1912.  


******
#  2. Integración y selección de los datos de interés a analizar.
******

## 2.1 Integración de los datos y análisis inicial

Cargamos los datos mediante la función read.csv: 

```{r message= FALSE, warning=FALSE}
data <- read.csv("titanic.csv", sep=",")
```

Empezaremos haciendo un breve análisis de los datos, ya que nos interesa tener una idea general de los datos que disponemos. 

Para empezar, calculamos las dimensiones de la base de datos mediante la función dim. Obtenemos que disponemos de 891 registros o pasajeros (filas) y 12 variables (columnas). 
A continuación, utilizando la función summary, obtenemos un resumen sobre las variables del juego de datos.

```{r}
dim(data)
summary(data)
```

Efectivamente, vemos qué varibles son numéricas y cuáles son cadenas de caracteres. Además, de las variables numéricas, obtenemos su mínimo, máximo, media y cuartiles.

Es importante notar que se han detectado valores vacíos en la variable Age. Más adelante hablaremos de esto.  

Para las variables carácter, realizaremos una pequeña tranformación, que nos aportará más información: las pasaremos a variable factor. Por último, también pasaremos a factor la variable Survived, ya que su interpretación es cualitativa y no cuantitativa. Ídem para la variable Pclass.  
```{r}
data$Name <- as.factor(data$Name)
data$Sex <- as.factor(data$Sex)
data$Ticket <- as.factor(data$Ticket)
data$Cabin <- as.factor(data$Cabin)
data$Embarked <- as.factor(data$Embarked)
data$Survived <- as.factor(data$Survived)
data$Survived <- factor(data$Survived, levels = c(0,1), labels=c("Deceased", "Survived")) 
data$Pclass <- as.factor(data$Pclass)
data$Pclass <- factor(data$Pclass, levels = c(1,2,3), labels=c("1st", "2st", "3st")) 
summary(data)
```
Como se puede observar, gracias a este cambio, ahora la función summary nos aporta un poco más de información. Vemos las cantidades de pasajeros agrupados por sexo, clase de billete, supervivencia, etc. 

Veremos un poco por encima el aspecto de los registros del dataset. Para esto, utilizamos la función str. 
```{r}
str(data)
```

## 2.2 Selección de los datos de interés a analizar

Llegados a este punto, podemos empezar a pensar que hay ciertas variables que no van a ser útiles para nuestro cometido. Se va a estudiar que factores determinan más la probabilidad de que un pasajero sobreviva. Por lo tanto, las variables que no aporten mucha información útil, quedan descartadas para nuestro objetivo.  

Para este caso, vamos a mantener en el dataset únicamente las siguientes variables: Survived, Pclass, Sex, Age. El resto de variables, se considera menos relevante (o nada relevante) para valorar en nuestro cometido. 

```{r}
data <- data[-c(1,4,7:12)] 
```

******
# 3. Limpieza de datos
******
En el análisis inicial, ya hemos realizado alguna pequeña transformación de preprocesado de datos. Procederemos ahora a analizar la presencia de outliers y valores vacíos. 


## 3.1 Valores vacíos.

Es de gran interés saber si tenemos muchos valores nulos y la distribución de éstos por variables.

Así pues, analizamos su presencia en nuestro nuevo dataset. 

```{r}
colSums(is.na(data))
```

Como podemos ver, la variable Age es la única que presenta valores vacíos, 177 en total. Para solventar este problema, se ha decidido substituir los valores NA por valores aleatorios entre la media de la variable menos la desviación típica y la media más la desviación típica (mean-sd, mean+sd).

Procedemos a substituir:

```{r}
a <- mean(data$Age[!is.na(data$Age)])
b <- sd(data$Age[!is.na(data$Age)])
data$Age[is.na(data$Age)] <- runif(177, a-b, a+b)
colSums(is.na(data))
summary(data$Age)
```
Comprovamos que efectivamente los cambios se han realizado y que nuestro dataset ya no contiene valores vacíos. Además, mediante la función summary comprobamos como las sustituciones realizadas no modifican, en gran medida, la distribucción de los datos (la media y los cuartiles se quedan prácticamente igual).


## 3.2 Valores extremos. 

Por la naturaleza del cometido y de nuestro dataset, tenemos una mayoría de variables factor. Como los outliers o valores extremos solo se pueden presentar en variables cuantitativas, solo habrá que analizar su presencia en la variable Age.


```{r}
boxplot(data$Age,  main = "Age")
boxplot.stats(data$Age)
```

Gracias a los diagramas de caja, vemos que claramente los valores extremos que se observan son plausibles dentro de la situación analizada. Por lo tanto, no se considera que necesiten ningún tipo de tratamiento adicional.

******
# 4. Análisis de los datos 
******

Nos interesa describir la relación entre la supervivencia y cada una de las variables mencionadas anteriormente. 
Para ello, se realizarán tres métodos de análisis diferentes. 

En primer lugar, un análisis visual. Graficaremos mediante diagramas de barras la cantidad de muertos y supervivientes según la clase en la que viajaban, la edad y  el sexo. Por otro lado, para obtener los datos que estamos graficando, utilizaremos el comando table para dos (y tres) variables que nos proporcionan las tablas de contingencia. Extraeremos las conclusiones a partir de estos gráficos y tablas. 

En segundo lugar, realizaremos un árbol de decisión para obtener unas reglas de asociación que nos permitan entender como influyen las variables al hecho de sobrevivir. 

Para acabar, realizaremos una regresión logística y calcularemos los respectivos Odds ratio e intervalos de confianza, para determinar como afecta una variable concreta a la probabilidad de supervivencia. 


## 4.1 Normalidad y homogeniedad de varianzas

Antes de todo, comprovaremos la normalidad de la variable Age. Para el resto de variables consideradas, no tiene sentido valorar que sigan una distribucción normal ya que no son cuantitativas.

```{r echo=TRUE, message=FALSE, warning=FALSE}

ggplot(data = data, aes(x = Age)) +
  geom_histogram(aes(y = ..density.., fill = ..count..)) +
  scale_fill_gradient(low = "#DCDCDC", high = "#7C7C7C") +
  stat_function(fun = dnorm, colour = "firebrick",
                args = list(mean = mean(data$Age),
                            sd = sd(data$Age))) +
  ggtitle("Histograma con curva normal teórica") +
  theme_bw()
```

El análisis visual permite preveer que la variable Age no acaba de seguir una distribucción normal. Lo comprovaremos numéricamente mediante el test de Shapiro-Wilk, para un nivel de significación del 5%. 

```{r}
shapiro.test(data$Age)
```

El test indica una p-value por debajo del nivel de significación 0.05, cosa que implica que la hipótesis nula (normalidad de los datos), puede ser rechazada. Es decir, confirmamos que la variable Age  no sigue una distribucción normal. 


En cuanto al análisis de homogeneidad de la varianza, en nuestro dataset dada la escasez de variables cuantitativas, solo podemos plantearnos la homegeniedad de la varianza sobre la variable Age. Si escogemos dos subconjuntos de los registros de Age, estos deberían tener una varianza significativamente parecida, para que al compararlos después, los resultados tengan más credibilidad. Para comprovarlo, realizaremos el test de Fligner-Killeen, dado que éste es útil cuando no hay normalidad (comprovado anteriormente).

En nuestro caso, vamos a considerar los subgrupos de supervivientes y no supervivientes, por lo tanto, nuestro test se realizará en función de la variable factor Survived. 

```{r}
fligner.test(Age ~ Survived, data = data)
```

Dado que la p-value es superior a 0.05, concluimos que no se encuentran diferencias significativas entre las varianzas de los subconjuntos de datos seleccionados.

Cabe destacar que, en nuestro dataset, este análisis no es muy útil, ya que la variable Age no es la variable dependiente, sino una de las independientes del modelo. Este tipo de análisis, son más útiles a la hora de, por ejemplo, comparar precios entre diferentes subconjuntos de datos, por ejemplo, casas vendidas en España y fuera de España, ya que el precio suele ser la variable dependiente. 

Aclarado esto, pasemos ahora con los tres análisis a partir del dataset. 

## 4.2 Análisis visual

Empezemos con el análisis visual. Para facilitar la extracción de información, discretizaremos la variable Age antes de graficar. 

```{r}
age_seg <- cut(data$Age, breaks = c(0,16,100), labels = c("Menor", "Adulto"))
grid.newpage()
plotbyClass<-ggplot(data,aes(Pclass, fill=Survived))+geom_bar() +labs(x="Class", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("black","green"))+ggtitle("Survived by Class")
plotbyAge<-ggplot(data,aes(age_seg, fill=Survived))+geom_bar() +labs(x="Age", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("black","green"))+ggtitle("Survived by Age")
plotbySex<-ggplot(data,aes(Sex, fill=Survived))+geom_bar() +labs(x="Sex", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("black","green"))+ggtitle("Survived by Sex")
grid.arrange(plotbyClass,plotbyAge,plotbySex,ncol=3)
```

Con estos gráficos obtenemos información muy valiosa que complementamos con las tablas de contingencia (listadas abajo). 

Por un lado, vemos que la tasa de supervivencia en mujeres es muchísimo más alta que en hombres. Este hecho es especialmente notable cuando observamos los porcentajes de supervivencia (74.2% en mujeres y 18.8% en hombres).

En cuanto a la clase, los pasajeros que viajaban en primera clase fueron los únicos cuyo porcentaje de supervivencia era mayor que el de mortalidad. El 63% de los viajeros de primera clase sobrevivió, por el 47.2% de los que viajaban en segunda clase y el 24.2% de los viajeros de tercera. 

Para finalizar, destacamos que la presencia de pasajeros adultos (mayores de 16) era mucho mayor que la de los niños (105 menores y 786 adultos). Asimismo, la tasa de supervivencia en niños fue bastante mayor (53% en menores, 36% en adultos aproximadamente). No podemos obviar, en cambio, que prácticamente la totalidad de los menores fallecidos eran de tercera clase (1 en primera clase, 2 en segunda, 42 en tercera).

NOTA: las cifras y porcentajes en el apartado de la edad pueden variar ligeramente debido a que hemos estimado, parte de la muestra, con datos pseudoaleatorios. Las conclusiones extraidas son siempre las mismas. 

```{r}
tabla1 <- table(data$Sex, data$Survived)
tabla1
prop.table(tabla1, margin = 1)
```

```{r}
tabla2 <- table(data$Pclass, data$Survived)
tabla2
prop.table(tabla2, margin = 1)
```

```{r}
tabla3 <- table(age_seg, data$Survived)
tabla3
prop.table(tabla3, margin = 1)
```

```{r}
tabla4 <- table(age_seg, data$Survived, data$Pclass)
tabla4
```

De forma adicional, podemos graficar las tablas de contigencia, que aportan visualmente la información que acabamos de ver pero de una manera más compacta. 

```{r}
par(mfrow=c(1,3))
plot(tabla1, col = c("black","green"), main = "SURVIVED vs. SEX")
plot(tabla2, col = c("black","green"), main = "SURVIVED vs. CLASS")
plot(tabla3, col = c("black","green"), main = "SURVIVED vs. AGE")
```


## 4.3 Árbol de decisión

Nuestro objetivo es crear un árbol de decisión que permita analizar qué tipo de pasajero del Titanic tenía probabilidades de sobrevivir o no. 

Dividimos el dataset en el set de entrenamiento y en el de prueba. Este último, lo utilizaremos para comprobar la calidad del modelo. Se ha decidido utilizar una proporción de registros de 2/3 y 1/3 para el set de entreamineto y set de prueba respectivamente. 

Para evitar que al dividir el dataset se formen subconjuntos sesgados, "desordenamos" los registros con la función sample. 
```{r}
data$Age <- age_seg
set.seed(1)
data_random <- data[sample(nrow(data)),]
```

Definimos los subconjuntos y creamos el árbol de decisión. En este caso, se ha utilizado la función C50, incluida en el package "C50". 
```{r}
set.seed(666)
y <- data_random[,1] 
X <- data_random[,2:4] 
indexes = sample(1:nrow(data), size=floor((2/3)*nrow(data)))
trainX<-X[indexes,]
trainy<-y[indexes]
testX<-X[-indexes,]
testy<-y[-indexes]
trainy = as.factor(trainy)
model <- C50::C5.0(trainX, trainy, rules = T)
summary(model)
```


El apartado Errors muestra el número y porcentaje de casos mal clasificados en el subconjunto de entrenamiento. 

El árbol obtenido clasifica erróneamente 121 de los 594 casos dados, una tasa de error de aproximadamente un 20.4%.

A partir del árbol de decisión que hemos modelado, extraemos las siguientes conclusiones a partir de las reglas: 

Sex = "Hombre" → Muere. Validez: 82%

Pclass = "3a" → Muere. Validez: 77%

Pclass = "1ª" o "2ª" y SEX = "Mujer" → Sobrevive. Validez: 93%

Por tanto, el conocimiento extraido se puede resumir a grosso modo como "las mujeres y los niños primero a excepción de que fueras de 3ª clase".

NOTA: de nuevo, al tratar con cierta aleatoriedad en el proceso, los porcentajes y cifras pueden variar ligeramente cada vez que ejecutamos el código. 

A continuación, se muestra el árbol obtenido.

```{r}
model <- C50::C5.0(trainX, trainy)
plot(model)
```

Una vez tenemos el modelo, podemos comprobar su calidad con el set de prueba. 

```{r}
predicted_model <- predict( model, testX, type="class" )
print(sprintf("La precisión del árbol es: %.4f %%",100*sum(predicted_model == testy) / length(predicted_model)))
```

Obtenemos una precisión del modelo de un 77% aproximadamente, cosa que nos indica que el modelo es bastante bueno. 

Para acabar, utilizamos el paquete gmodelos, para obtener la información detallada de la calidad de la predicción. 
```{r}
CrossTable(testy, predicted_model,prop.chisq  = FALSE, prop.c = FALSE, prop.r =FALSE,dnn = c('Reality', 'Prediction'))
```

## 4.4 Regresión logística

Se pretende responder a la pregunta siguiente: ¿Qué probabilidad se tiene de sobrevivir en el Titanic siendo mujer respecto a ser hombre?

Realizaremos un modelo de regresión logística para determinar las probabilidades de este hecho. 

```{r message= FALSE, warning=FALSE}
logit <- glm(Survived ~ Sex, data=data, family = "binomial"(link = "logit"))
summary(logit)
```

Podemos extraer cierta información del gráfico anterior. En primer lugar, la edad es significativa para determinar si una persona sobrevive o no (Pr(>|z|) < 0.05). En segundo lugar, el valor Estimate negativo indica que ser hombre es un factor que resta posibilidades de sobrevivir en el Titanic, como venimos viendo anteriormente. 

Calculamos el estimador del Odd Ratio y los intervalos de confianza. 

```{r message= FALSE, warning=FALSE}
exp(coefficients(logit))
exp(confint(logit))
```

Se tiene un OR de 0.08, con lo que la probabilidad de sobrevivir siendo hombre es 0.08 veces menor respecto a sobrevivir siendo mujer.   

Dada la información del IC, deducimos que la supervivencia siendo hombre es entre 0.058 y 0.111 veces menos probable que la supervivencia siendo mujer.  

Para acabar, creamos el fichero .csv resultante:
```{r message= FALSE, warning=FALSE}
write.csv(data, "titanic_clean.csv")
```

******
# 5. Referencias 
******

C50 Package Documentation: https://cran.r-project.org/web/packages/C50/C50.pdf

Ramon Sangüesa i Solé: Clasificación: árboles de decisión. PID_00165729

Luis Carlos Molina Félix y Ramon Sangüesa i Solé: Reglas de asociación. PID_00165732

Montserrat Guillén Estany y María Teresa Alonso Alonso. Modelos de regresión logística. PID_00276229

https://es.wikipedia.org/wiki/Test_de_Shapiro%E2%80%93Wilk

https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/shapiro.test

https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/fligner.test
